{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratory 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Training a multi-linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1917,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1\n",
    "Write a function that reads in the data from a CIFAR-10 batch file and returns the image and label data in separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1918,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filename):\n",
    "    with open('dataset/'+filename, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def one_hot_labels(labels, num_distincts=10):\n",
    "    one_hot = np.zeros((num_distincts, len(labels)))\n",
    "    for i, label in enumerate(labels):\n",
    "        one_hot[label, i] = 1\n",
    "    return one_hot\n",
    "\n",
    "def LoadBatch(filename):\n",
    "    dict = load_file(filename)\n",
    "    images = dict[b'data'].T\n",
    "    labels = dict[b'labels']\n",
    "    labels_one_hot = one_hot_labels(labels)\n",
    "    return images, labels_one_hot ,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1919,
   "metadata": {},
   "outputs": [],
   "source": [
    "filetrain = 'data_batch_1'\n",
    "fileval = 'data_batch_2'\n",
    "filetest = 'test_batch'\n",
    "\n",
    "X_train, labels_oh_train, labels_train = LoadBatch(filetrain)\n",
    "X_val, labels_oh_val, labels_val = LoadBatch(fileval)\n",
    "X_test, labels_oh_test, labels_test = LoadBatch(filetest)\n",
    "batches = load_file('batches.meta')[b'label_names']\n",
    "label_names = [lable_name.decode('utf-8') for lable_name in batches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label distribution in the three subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1920,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_list = [labels_train, labels_val, labels_test]\n",
    "names_list = ['Images batch '+str(i) for i in ['Train', 'Validation', 'Test']]\n",
    "_, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i, (labels, name) in enumerate(zip(labels_list, names_list)):\n",
    "    # Plot the histogram of the labels\n",
    "    axes[i].bar(np.arange(10), np.bincount(labels), align='center', alpha=1)\n",
    "    axes[i].set_title(name)\n",
    "    axes[i].set_xlabel('Label')\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].set_xticks(np.arange(10))\n",
    "    axes[i].set_xticklabels(label_names, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2\n",
    "Next we should pre-process the raw input data as it helps training. You should transform training data to have zero mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1921,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    mean = np.mean(data, axis=1, keepdims=True)\n",
    "    std = np.std(data, axis=1, keepdims=True)\n",
    "    return (data - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3\n",
    "After reading in and pre-processing the data, you can initialize the parameters of the model W and b as you now know what size they should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1922,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(input_dim, output_dim, seed=42, mean=0, std=0.01):\n",
    "    #np.random.seed(seed)\n",
    "    W = np.random.normal(mean, std, (output_dim, input_dim))\n",
    "    #np.random.seed(seed)\n",
    "    b = np.random.normal(mean, std, (output_dim, 1))\n",
    "\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1923,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00651786  0.00385985  0.00070475 ...  0.00332621  0.02814807\n",
      "   0.00348684]\n",
      " [ 0.00333376 -0.00472171 -0.01930174 ... -0.00446102  0.00254311\n",
      "  -0.01013527]\n",
      " [-0.00751627 -0.00673357 -0.00365043 ...  0.00431495  0.00408036\n",
      "   0.00684132]\n",
      " ...\n",
      " [-0.01157909  0.00630458  0.0047351  ...  0.00740804 -0.00315616\n",
      "  -0.0089477 ]\n",
      " [ 0.01221352  0.01068417 -0.01128368 ... -0.01331343 -0.00025538\n",
      "   0.00953224]\n",
      " [-0.01278417 -0.0091013  -0.00598186 ... -0.00545418  0.00453613\n",
      "   0.01002823]]\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[0]\n",
    "output_dim = labels_oh_train.shape[0]\n",
    "W, b = initialize_weights(input_dim, output_dim)\n",
    "W.shape, b.shape\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4\n",
    "Write a function that evaluates the network function, i.e. equations (1, 2), on multiple images and returns the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1924,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\" Standard definition of the softmax function \"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def EvaluateClassifier(X, W, b):\n",
    "    # eq 1,2\n",
    "    s = W.dot(X) + b\n",
    "    p = softmax(s)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1925,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 1925,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvaluateClassifier(X_train[:,0:100], W, b).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5\n",
    "Write the function that computes the cost function given by equation for a set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1926,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(X, y, W, b, lamda):\n",
    "    # eq 5\n",
    "    p = EvaluateClassifier(X, W, b)\n",
    "    # loss function term\n",
    "    loss_cross = sum(-np.log((y*p).sum(axis=0)))\n",
    "    # regularization term\n",
    "    regularization = lamda * np.sum(W**2)\n",
    "    # total cost\n",
    "    J = loss_cross/X.shape[1] + regularization\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6\n",
    "Write a function that computes the accuracy of the network’s predictions on a set of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1927,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAccuracy(X, y, W, b):\n",
    "    # eq 4\n",
    "    p = EvaluateClassifier(X, W, b)\n",
    "    predictions = np.argmax(p, axis=0)\n",
    "    accuracy = np.mean(predictions == y)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7\n",
    "Write the function that evaluates, for a mini-batch, the gradients of the cost function w.r.t. W and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1928,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeGradients(X, y, p, W, lamda):\n",
    "    # eq 10, 11\n",
    "    n = X.shape[1]\n",
    "    C = y.shape[0]\n",
    "    G = -(y-p)\n",
    "    grad_W = (G@X.T)/n+2*lamda*W\n",
    "    grad_b = (G@np.ones(shape=(n,1))/n).reshape(C,1)\n",
    "    \n",
    "    return grad_W, grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerically computed gradient with finite difference method and centered difference formula (slower but more accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1929,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeGradsNum(X, Y, P, W, b, lamda, h):\n",
    "    \"\"\" Converted from matlab code \"\"\"\n",
    "    no = W.shape[0]\n",
    "    # d = X.shape[0]\n",
    " \n",
    "    grad_w = np.zeros(W.shape)\n",
    "    grad_b = np.zeros((no, 1))\n",
    " \n",
    "    c = computeCost(X, Y, W, b, lamda)\n",
    " \n",
    "    for i in range(len(b)):\n",
    "        b_try = np.array(b)\n",
    "        b_try[i] += h\n",
    "        c2 = computeCost(X, Y, W, b_try, lamda)\n",
    "        grad_b[i] = (c2 - c) / h\n",
    " \n",
    "    for i in range(W.shape[0]):\n",
    "        for j in range(W.shape[1]):\n",
    "            w_try = np.array(W)\n",
    "            w_try[i, j] += h\n",
    "            c2 = computeCost(X, Y, w_try, b, lamda)\n",
    "            grad_w[i, j] = (c2 - c) / h\n",
    " \n",
    "    return [grad_w, grad_b]\n",
    "\n",
    "def computeGradsNumSlow(X, Y, P, W, b, lamda, h):\n",
    "    no = W.shape[0]\n",
    " \n",
    "    grad_w = np.zeros(W.shape)\n",
    "    grad_b = np.zeros((no, 1))\n",
    " \n",
    "    for i in range(len(b)):\n",
    "        b_try = np.array(b)\n",
    "        b_try[i] -= h\n",
    "        c1 = computeCost(X, Y, W, b_try, lamda)\n",
    " \n",
    "        b_try = np.array(b)\n",
    "        b_try[i] += h\n",
    "        c2 = computeCost(X, Y, W, b_try, lamda)\n",
    " \n",
    "        grad_b[i] = (c2 - c1) / (2 * h)\n",
    " \n",
    "    for i in range(W.shape[0]):\n",
    "        for j in range(W.shape[1]):\n",
    "            w_try = np.array(W)\n",
    "            w_try[i, j] -= h\n",
    "            c1 = computeCost(X, Y, w_try, b, lamda)\n",
    " \n",
    "            w_try = np.array(W)\n",
    "            w_try[i, j] += h\n",
    "            c2 = computeCost(X, Y, w_try, b, lamda)\n",
    " \n",
    "            grad_w[i, j] = (c2 - c1) / (2 * h)\n",
    " \n",
    "    return [grad_w, grad_b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check difference between numerical and analytical gradient for the first 20 dimensions of the first training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1930,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.89999862e+01 4.29999900e+01 4.99999883e+01 ... 1.39999967e+02\n",
      "  8.39999804e+01 7.19999832e+01]\n",
      " [7.83517794e-24 5.71038393e-24 6.63998131e-24 ... 1.85919477e-23\n",
      "  1.11551686e-23 9.56157308e-24]\n",
      " [1.72867198e-15 1.25987958e-15 1.46497625e-15 ... 4.10193351e-15\n",
      "  2.46116010e-15 2.10956580e-15]\n",
      " ...\n",
      " [2.20027925e-69 1.60359335e-69 1.86464343e-69 ... 5.22100160e-69\n",
      "  3.13260096e-69 2.68508654e-69]\n",
      " [1.06649068e-05 7.77272866e-06 9.03805658e-06 ... 2.53065584e-05\n",
      "  1.51839351e-05 1.30148015e-05]\n",
      " [4.93997390e-25 3.60031996e-25 4.18641856e-25 ... 1.17219720e-24\n",
      "  7.03318318e-25 6.02844272e-25]]\n",
      "[[ 9.99999766e-001]\n",
      " [ 1.32799626e-025]\n",
      " [ 2.92995250e-017]\n",
      " [ 6.11183743e-112]\n",
      " [ 3.93491405e-029]\n",
      " [ 5.28813590e-008]\n",
      " [-1.00000000e+000]\n",
      " [ 3.72928686e-071]\n",
      " [ 1.80761132e-007]\n",
      " [ 8.37283712e-027]]\n",
      "For weights: 100.0% of absolute errors below 1e-6\n",
      "For bias: 100.0% of absolute errors below 1e-6\n",
      "For weights (slow): 100.0% of absolute errors below 1e-6\n",
      "For bias (slow): 100.0% of absolute errors below 1e-6 \n",
      "\n",
      "For weights the maximum absolute error is: 2.0602300310201827e-08\n",
      "For bias the maximum absolute error is: 1.0466796984687221e-08\n",
      "For weights (slow) the maximum absolute error is: 1.3248410368760233e-08\n",
      "For bias (slow) the maximum absolute error is: 3.97997974232508e-09 \n",
      "\n",
      "For weights: 80.04557291666666% of relative errors below 1e-6\n",
      "For bias: 80.0% of relative errors below 1e-6\n",
      "For weights (slow): 80.07486979166667% of relative errors below 1e-6\n",
      "For bias (slow): 80.0% of relative errors below 1e-6 \n",
      "\n",
      "For weights the maximum relative error is: 0.008611410079462915\n",
      "For bias the maximum relative error is: 0.0039799797423250806\n",
      "For weights (slow) the maximum relative error is: 0.003274769531101719\n",
      "For bias (slow) the maximum relative error is: 0.0039799797423250806\n"
     ]
    }
   ],
   "source": [
    "X = X_train[0:10000, [0]]\n",
    "y = labels_oh_train[:, [0]]\n",
    "lamda = 0\n",
    "\n",
    "p = EvaluateClassifier(X, W[:,0:10000], b)\n",
    "grad_w_analytic, grad_b_analytic = computeGradients(X, y, p, W[:,0:10000], lamda)\n",
    "grad_w_numeric, grad_b_numeric = computeGradsNum(X, y, p, W[:,0:10000], b, lamda, 1e-6)\n",
    "grad_w_numeric_slow, grad_b_numeric_slow = computeGradsNumSlow(X, y, p, W[:,0:10000], b, lamda, 1e-6)\n",
    "\n",
    "print(grad_w_analytic)\n",
    "print(grad_b_analytic)\n",
    "# Absolute error\n",
    "grad_W_abs_error = np.abs(grad_w_analytic - grad_w_numeric)\n",
    "grad_b_abs_error = np.abs(grad_b_analytic - grad_b_numeric)\n",
    "grad_W_abs_error_slow = np.abs(grad_w_analytic - grad_w_numeric_slow)\n",
    "grad_b_abs_error_slow = np.abs(grad_b_analytic - grad_b_numeric_slow)\n",
    "\n",
    "print('For weights: '+str(np.mean(grad_W_abs_error<1e-6)*100)+\"% of absolute errors below 1e-6\")\n",
    "print('For bias: '+str(np.mean(grad_b_abs_error<1e-6)*100)+\"% of absolute errors below 1e-6\")\n",
    "print('For weights (slow): '+str(np.mean(grad_W_abs_error_slow<1e-6)*100)+\"% of absolute errors below 1e-6\")\n",
    "print('For bias (slow): '+str(np.mean(grad_b_abs_error_slow<1e-6)*100)+\"% of absolute errors below 1e-6\", '\\n')\n",
    "print('For weights the maximum absolute error is: '+str(np.max(grad_W_abs_error)))\n",
    "print('For bias the maximum absolute error is: '+str(np.max(grad_b_abs_error)))\n",
    "print('For weights (slow) the maximum absolute error is: '+str(np.max(grad_W_abs_error_slow)))\n",
    "print('For bias (slow) the maximum absolute error is: '+str(np.max(grad_b_abs_error_slow)), '\\n')\n",
    "\n",
    "# Relative error\n",
    "grad_W_rel_error = np.abs(grad_w_analytic - grad_w_numeric)/np.maximum(1e-6, np.abs(grad_w_analytic) + np.abs(grad_w_numeric))\n",
    "grad_b_rel_error = np.abs(grad_b_analytic - grad_b_numeric)/np.maximum(1e-6, np.abs(grad_b_analytic) + np.abs(grad_b_numeric))\n",
    "grad_W_rel_error_slow = np.abs(grad_w_analytic - grad_w_numeric_slow)/np.maximum(1e-6, np.abs(grad_w_analytic) + np.abs(grad_w_numeric_slow))\n",
    "grad_b_rel_error_slow = np.abs(grad_b_analytic - grad_b_numeric_slow)/np.maximum(1e-6, np.abs(grad_b_analytic) + np.abs(grad_b_numeric_slow))\n",
    "\n",
    "print('For weights: '+str(np.mean(grad_W_rel_error<1e-6)*100)+\"% of relative errors below 1e-6\")\n",
    "print('For bias: '+str(np.mean(grad_b_rel_error<1e-6)*100)+\"% of relative errors below 1e-6\")\n",
    "print('For weights (slow): '+str(np.mean(grad_W_rel_error_slow<1e-6)*100)+\"% of relative errors below 1e-6\")\n",
    "print('For bias (slow): '+str(np.mean(grad_b_rel_error_slow<1e-6)*100)+\"% of relative errors below 1e-6\", '\\n')\n",
    "print('For weights the maximum relative error is: '+str(np.max(grad_W_rel_error)))\n",
    "print('For bias the maximum relative error is: '+str(np.max(grad_b_rel_error)))\n",
    "print('For weights (slow) the maximum relative error is: '+str(np.max(grad_W_rel_error_slow)))\n",
    "print('For bias (slow) the maximum relative error is: '+str(np.max(grad_b_rel_error_slow)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using first 5 images with all dimensions and regularization parameter $\\lambda = 0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1931,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00651786  0.00385985  0.00070475 ...  0.00332621  0.02814807\n",
      "   0.00348684]\n",
      " [ 0.00333376 -0.00472171 -0.01930174 ... -0.00446102  0.00254311\n",
      "  -0.01013527]\n",
      " [-0.00751627 -0.00673357 -0.00365043 ...  0.00431495  0.00408036\n",
      "   0.00684132]\n",
      " ...\n",
      " [-0.01157909  0.00630458  0.0047351  ...  0.00740804 -0.00315616\n",
      "  -0.0089477 ]\n",
      " [ 0.01221352  0.01068417 -0.01128368 ... -0.01331343 -0.00025538\n",
      "   0.00953224]\n",
      " [-0.01278417 -0.0091013  -0.00598186 ... -0.00545418  0.00453613\n",
      "   0.01002823]]\n",
      "[[-0.01170179]\n",
      " [ 0.00319609]\n",
      " [ 0.01034182]\n",
      " [-0.01449604]\n",
      " [ 0.00457791]\n",
      " [ 0.01461237]\n",
      " [ 0.00732211]\n",
      " [ 0.00117104]\n",
      " [ 0.00575712]\n",
      " [ 0.00516681]]\n",
      "For weights: 40.625% of absolute errors below 1e-6\n",
      "For bias: 100.0% of absolute errors below 1e-6\n",
      "For weights (slow): 100.0% of absolute errors below 1e-6\n",
      "For bias (slow): 100.0% of absolute errors below 1e-6 \n",
      "\n",
      "For weights the maximum absolute error is: 0.00011922628043237182\n",
      "For bias the maximum absolute error is: 4.23928111503713e-08\n",
      "For weights (slow) the maximum absolute error is: 7.379937017049087e-08\n",
      "For bias (slow) the maximum absolute error is: 4.94982385079723e-08 \n",
      "\n",
      "For weights: 71.611328125% of relative errors below 1e-6\n",
      "For bias: 100.0% of relative errors below 1e-6\n",
      "For weights (slow): 99.990234375% of relative errors below 1e-6\n",
      "For bias (slow): 100.0% of relative errors below 1e-6 \n",
      "\n",
      "For weights the maximum relative error is: 0.009318438320366744\n",
      "For bias the maximum relative error is: 3.1552964226298943e-07\n",
      "For weights (slow) the maximum relative error is: 5.309066111151742e-06\n",
      "For bias (slow) the maximum relative error is: 1.7403991088987487e-07\n"
     ]
    }
   ],
   "source": [
    "X = X_train[:, 0:100]\n",
    "y = labels_oh_train[:, 0:100]\n",
    "lamda = 0.01\n",
    "print(W)\n",
    "print(b)\n",
    "\n",
    "p = EvaluateClassifier(X, W, b)\n",
    "grad_w_analytic, grad_b_analytic = computeGradients(X, y, p, W, lamda)\n",
    "grad_w_numeric, grad_b_numeric = computeGradsNum(X, y, p, W, b, lamda, 1e-6)\n",
    "grad_w_numeric_slow, grad_b_numeric_slow = computeGradsNumSlow(X, y, p, W, b, lamda, 1e-6)\n",
    "\n",
    "# Absolute error\n",
    "grad_W_abs_error = np.abs(grad_w_analytic - grad_w_numeric)\n",
    "grad_b_abs_error = np.abs(grad_b_analytic - grad_b_numeric)\n",
    "grad_W_abs_error_slow = np.abs(grad_w_analytic - grad_w_numeric_slow)\n",
    "grad_b_abs_error_slow = np.abs(grad_b_analytic - grad_b_numeric_slow)\n",
    "\n",
    "print('For weights: '+str(np.mean(grad_W_abs_error<1e-6)*100)+\"% of absolute errors below 1e-6\")\n",
    "print('For bias: '+str(np.mean(grad_b_abs_error<1e-6)*100)+\"% of absolute errors below 1e-6\")\n",
    "print('For weights (slow): '+str(np.mean(grad_W_abs_error_slow<1e-6)*100)+\"% of absolute errors below 1e-6\")\n",
    "print('For bias (slow): '+str(np.mean(grad_b_abs_error_slow<1e-6)*100)+\"% of absolute errors below 1e-6\", '\\n')\n",
    "print('For weights the maximum absolute error is: '+str(np.max(grad_W_abs_error)))\n",
    "print('For bias the maximum absolute error is: '+str(np.max(grad_b_abs_error)))\n",
    "print('For weights (slow) the maximum absolute error is: '+str(np.max(grad_W_abs_error_slow)))\n",
    "print('For bias (slow) the maximum absolute error is: '+str(np.max(grad_b_abs_error_slow)), '\\n')\n",
    "\n",
    "# Relative error\n",
    "grad_W_rel_error = np.abs(grad_w_analytic - grad_w_numeric)/np.maximum(1e-6, np.abs(grad_w_analytic) + np.abs(grad_w_numeric))\n",
    "grad_b_rel_error = np.abs(grad_b_analytic - grad_b_numeric)/np.maximum(1e-6, np.abs(grad_b_analytic) + np.abs(grad_b_numeric))\n",
    "grad_W_rel_error_slow = np.abs(grad_w_analytic - grad_w_numeric_slow)/np.maximum(1e-6, np.abs(grad_w_analytic) + np.abs(grad_w_numeric_slow))\n",
    "grad_b_rel_error_slow = np.abs(grad_b_analytic - grad_b_numeric_slow)/np.maximum(1e-6, np.abs(grad_b_analytic) + np.abs(grad_b_numeric_slow))\n",
    "\n",
    "print('For weights: '+str(np.mean(grad_W_rel_error<1e-6)*100)+\"% of relative errors below 1e-6\")\n",
    "print('For bias: '+str(np.mean(grad_b_rel_error<1e-6)*100)+\"% of relative errors below 1e-6\")\n",
    "print('For weights (slow): '+str(np.mean(grad_W_rel_error_slow<1e-6)*100)+\"% of relative errors below 1e-6\")\n",
    "print('For bias (slow): '+str(np.mean(grad_b_rel_error_slow<1e-6)*100)+\"% of relative errors below 1e-6\", '\\n')\n",
    "print('For weights the maximum relative error is: '+str(np.max(grad_W_rel_error)))\n",
    "print('For bias the maximum relative error is: '+str(np.max(grad_b_rel_error)))\n",
    "print('For weights (slow) the maximum relative error is: '+str(np.max(grad_W_rel_error_slow)))\n",
    "print('For bias (slow) the maximum relative error is: '+str(np.max(grad_b_rel_error_slow)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8\n",
    "Define the function for the mini-batch gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1932,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MiniBatchGD(X, Y, y, GDparams, W, b, X_val, Y_val, y_val, lamda=0):\n",
    "    n = X.shape[1]\n",
    "    eta = GDparams['eta']\n",
    "    n_batch = GDparams['n_batch']\n",
    "    n_epochs = GDparams['n_epochs']\n",
    "\n",
    "    W = W.copy()\n",
    "    b = b.copy()\n",
    "    X_orig = X.copy()\n",
    "    Y_orig = Y.copy()\n",
    "    y_orig = y.copy()\n",
    "\n",
    "    metrics = {'epochs': [], 'loss_train': [], 'accuracy_train': [], \n",
    "                'loss_val': [], 'accuracy_val': []}\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # permute data\n",
    "        permuted_idx = np.random.permutation(n)\n",
    "        X = X_orig[:, permuted_idx]\n",
    "        Y = Y_orig[:, permuted_idx]\n",
    "        y = [y_orig[i] for i in permuted_idx]\n",
    "\n",
    "        # iterate batches\n",
    "        for j in range(n//n_batch):\n",
    "            j_start = j*n_batch\n",
    "            j_end = (j+1)*n_batch\n",
    "            batch_idx = range(j_start, j_end)\n",
    "            X_batch = X[:, batch_idx]\n",
    "            Y_batch = Y[:, batch_idx]\n",
    "            y_batch = [y[i] for i in batch_idx]\n",
    "            \n",
    "            p = EvaluateClassifier(X_batch, W, b)\n",
    "            grad_W, grad_b = computeGradients(X_batch, Y_batch, p, W, lamda)\n",
    "            W += -eta*grad_W\n",
    "            b += -eta*grad_b\n",
    "            sys.stdout.write(grad_W)\n",
    "            sys.stdout.write(grad_b)\n",
    "            sys.stdout.write(W)\n",
    "            sys.stdout.write(b)\n",
    "\n",
    "        # compute metrics\n",
    "        metrics['epochs'].append(epoch)\n",
    "        metrics['loss_train'].append(computeCost(X, Y, W, b, lamda))\n",
    "        metrics['accuracy_train'].append(computeAccuracy(X, y, W, b))\n",
    "        metrics['loss_val'].append(computeCost(X_val, Y_val, W, b, lamda))\n",
    "        metrics['accuracy_val'].append(computeAccuracy(X_val, y_val, W, b))\n",
    "\n",
    "    return W, b, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1933,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(metrics, title=''):\n",
    "    # plot the accuracy on train and validation sets in the left subplot and loss in the right subplot\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax[0].plot(metrics['epochs'], metrics['accuracy_train'], label='train')\n",
    "    ax[0].plot(metrics['epochs'], metrics['accuracy_val'], label='validation')\n",
    "    ax[0].set_xlabel('epochs')\n",
    "    ax[0].set_ylabel('accuracy')\n",
    "    ax[0].set_title('Accuracy')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(metrics['epochs'], metrics['loss_train'], label='train')\n",
    "    ax[1].plot(metrics['epochs'], metrics['loss_val'], label='validation')\n",
    "    ax[1].set_xlabel('epochs')\n",
    "    ax[1].set_ylabel('loss')\n",
    "    ax[1].set_title('Loss')\n",
    "    ax[1].legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1934,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(W, labels, title=''):\n",
    "    fig, ax = plt.subplots(1, 10, figsize=(20, 2))\n",
    "    for i in range(10):\n",
    "        ax[i].imshow(W[i, :].reshape(32, 32, 3), interpolation='spline16')\n",
    "        ax[i].set_title(labels[i])\n",
    "        ax[i].axis('off')\n",
    "    \n",
    "        plt.suptitle(title, fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1935,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00651786  0.00385985  0.00070475 ...  0.00332621  0.02814807\n",
      "   0.00348684]\n",
      " [ 0.00333376 -0.00472171 -0.01930174 ... -0.00446102  0.00254311\n",
      "  -0.01013527]\n",
      " [-0.00751627 -0.00673357 -0.00365043 ...  0.00431495  0.00408036\n",
      "   0.00684132]\n",
      " ...\n",
      " [-0.01157909  0.00630458  0.0047351  ...  0.00740804 -0.00315616\n",
      "  -0.0089477 ]\n",
      " [ 0.01221352  0.01068417 -0.01128368 ... -0.01331343 -0.00025538\n",
      "   0.00953224]\n",
      " [-0.01278417 -0.0091013  -0.00598186 ... -0.00545418  0.00453613\n",
      "   0.01002823]]\n",
      "[[-0.01170179]\n",
      " [ 0.00319609]\n",
      " [ 0.01034182]\n",
      " [-0.01449604]\n",
      " [ 0.00457791]\n",
      " [ 0.01461237]\n",
      " [ 0.00732211]\n",
      " [ 0.00117104]\n",
      " [ 0.00575712]\n",
      " [ 0.00516681]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1935], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(W)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(b)\n\u001b[0;32m----> 5\u001b[0m W, b, metrics \u001b[38;5;241m=\u001b[39m MiniBatchGD(X_train, labels_oh_train, labels_train, GDparams, W, b, X_val, labels_oh_val, labels_val, lmb)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy_val\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy_train\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn [1932], line 37\u001b[0m, in \u001b[0;36mMiniBatchGD\u001b[0;34m(X, Y, y, GDparams, W, b, X_val, Y_val, y_val, lamda)\u001b[0m\n\u001b[1;32m     35\u001b[0m W \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39meta\u001b[38;5;241m*\u001b[39mgrad_W\n\u001b[1;32m     36\u001b[0m b \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39meta\u001b[38;5;241m*\u001b[39mgrad_b\n\u001b[0;32m---> 37\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_W\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(grad_b)\n\u001b[1;32m     39\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(W)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/ipykernel/iostream.py:529\u001b[0m, in \u001b[0;36mOutStream.write\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[39m\"\"\"Write to current stream after encoding if necessary\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \n\u001b[1;32m    521\u001b[0m \u001b[39mReturns\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    525\u001b[0m \n\u001b[1;32m    526\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(string, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 529\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwrite() argument must be str, not \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(string)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    531\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mecho \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "lmb = 0\n",
    "GDparams = {'eta': 0.01, 'n_batch': 100, 'n_epochs': 40}\n",
    "print(W)\n",
    "print(b)\n",
    "W, b, metrics = MiniBatchGD(X_train, labels_oh_train, labels_train, GDparams, W, b, X_val, labels_oh_val, labels_val, lmb)\n",
    "\n",
    "print(metrics['accuracy_val'])\n",
    "print(metrics['accuracy_train'])\n",
    "\n",
    "plot_curves(metrics, title='Without regularization')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "195db2848eee62c9ff7fd3d4d90ed470b85a4cc6750fa0c207c4e3af1e5ca207"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
